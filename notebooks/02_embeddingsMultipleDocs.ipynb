{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI vs Local Embeddings\n",
    "\n",
    "Performance comparison:\n",
    "- OpenAI's Embeddings Model\n",
    "- InstructorEmbedding at [Huggingface](https://huggingface.co/hkunlp/instructor-xl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment variables and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader, AirbyteJSONLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstructorEmbedding \n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "# OpenAI Embedding\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Multiple files from Directory (json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will upload all MPDL project files using the `langchain.document_loaders.TextLoader`. The following script iterates over the files in this repository and loads every `.json` file (a.k.a. **documents**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import AirbyteJSONLoader\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = DirectoryLoader(f'{root_dir}/mpdl_collection/', glob='**/*.json', show_progress=True, loader_cls=TextLoader)\n",
    "# documents = loader.load()\n",
    "# print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all repos\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    root_dir + \"/mpdl_collection_raw\",\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".json\"],\n",
    "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),\n",
    ")\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the `Document` into chunks for embedding and vector storage. We can use `RecursiveCharacterTextSplitter` with language specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=1000,\n",
    "#     chunk_overlap=100\n",
    "# )\n",
    "# texts = text_splitter.split_documents(documents)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "texts = python_splitter.split_documents(documents[:5]) # only 5 documents as it gets so long to compute embeddings\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\\n    \"somef_provenance\": {\\n        \"somef_version\": \"0.9.4\",\\n        \"somef_schema_version\": \"1.0.0\",\\n        \"date\": \"2023-11-28 15:24:34\"\\n    },\\n    \"code_repository\": [\\n        {\\n            \"result\": {\\n                \"value\": \"https://github.com/MPDL/screenshot-service\",\\n                \"type\": \"Url\"\\n            },\\n            \"confidence\": 1,\\n            \"technique\": \"GitHub_API\"\\n        }\\n    ],\\n    \"owner\": [\\n        {\\n            \"result\": {\\n                \"value\": \"MPDL\",\\n                \"type\": \"Organization\"\\n            },\\n            \"confidence\": 1,\\n            \"technique\": \"GitHub_API\"\\n        }\\n    ],\\n    \"date_created\": [\\n        {\\n            \"result\": {\\n                \"value\": \"2014-08-05T09:14:41Z\",\\n                \"type\": \"Date\"\\n            },\\n            \"confidence\": 1,\\n            \"technique\": \"GitHub_API\"\\n        }\\n    ],\\n    \"date_updated\": [\\n        {\\n            \"result\": {\\n                \"value\": \"2015-10-05T15:09:42Z\",\\n                \"type\": \"Date\"\\n            },\\n            \"confidence\": 1,\\n            \"technique\": \"GitHub_API\"\\n        }\\n    ],\\n    \"license\": [\\n        {\\n            \"result\": {\\n                \"value\": \"https://api.github.com/licenses/apache-2.0\",\\n                \"type\": \"License\",\\n                \"name\": \"Apache License 2.0\",\\n                \"url\": \"https://api.github.com/licenses/apache-2.0\",\\n                \"spdx_id\": \"Apache-2.0\"\\n            },\\n            \"confidence\": 1,\\n            \"technique\": \"GitHub_API\"\\n        },\\n        {\\n            \"result\": {' metadata={'source': '/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json', 'language': <Language.PYTHON: 'python'>}\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA\n",
    "\n",
    "We need to store the documents in a way we can semantically search for their content. The most common approach is to embed the contents of each document then store the embedding and document in a vector store. When setting up the vectorstore retriever:\n",
    "- We test max marginal relevance for retrieval\n",
    "- And 8 documents returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import Chroma\n",
    "\n",
    "# db = Chroma.from_documents(texts, OpenAIEmbeddings(disallowed_special=()))\n",
    "# retriever = db.as_retriever(\n",
    "#     search_type=\"mmr\",  # Also test \"similarity\"\n",
    "#     search_kwargs={\"k\": 8},\n",
    "# search_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embeddings for MPDL document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss # for similarilty: https://faiss.ai/index.html\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings(docs, embeddings, sotre_name, path):\n",
    "    vectorStore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    with open(f\"{path}/faiss_{sotre_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(vectorStore, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(sotre_name, path):\n",
    "    with open(f\"{path}/faiss_{sotre_name}.pkl\", \"rb\") as f:\n",
    "        VectorStore = pickle.load(f)\n",
    "    return VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HF Instructor Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "                                                      model_kwargs={\"device\": \"cpu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/Embedding_store\n"
     ]
    }
   ],
   "source": [
    "Embedding_store_path = f\"{root_dir}/Embedding_store\"\n",
    "print(Embedding_store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.vectorstores.faiss.FAISS object at 0x3dd2c31d0>\n"
     ]
    }
   ],
   "source": [
    "db_instructEmbedd = FAISS.from_documents(texts, instructor_embeddings)\n",
    "print(db_instructEmbedd) ## takes so long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db_instructEmbedd.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceInstructEmbeddings'] vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x3dd2c31d0> search_kwargs={'k': 3}\n"
     ]
    }
   ],
   "source": [
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='\"type\": \"Url\"\\n            },\\n            \"confidence\": 1,\\n            \"technique\": \"file_exploration\"\\n        }\\n    ],\\n    \"license\": [\\n        {\\n            \"result\": {\\n                \"value\": \"The MIT License (MIT)\\\\n\\\\nCopyright (c) 2016-2018 Christoph Broschinski\\\\n\\\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\\\nthis software and associated documentation files (the \\\\\"Software\\\\\"), to deal in\\\\nthe Software without restriction, including without limitation the rights to\\\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\\\\nof the Software, and to permit persons to whom the Software is furnished to do\\\\nso, subject to the following conditions:\\\\n\\\\nThe above copyright notice and this permission notice shall be included in all\\\\ncopies or substantial portions of the Software.\\\\n\\\\nTHE SOFTWARE IS PROVIDED \\\\\"AS IS\\\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\\\nTHE SOFTWARE.\\\\n\",\\n                \"type\": \"File_dump\"\\n            },\\n            \"confidence\": 1,\\n            \"technique\": \"file_exploration\",\\n            \"source\": \"https://raw.githubusercontent.com/MPDL/unibiAPC/master/python/LICENSE.md\"\\n        },\\n        {\\n            \"result\": {\\n                \"value\": \"The datasets are made available under the Open Database License: http://opendatacommons.org/licenses/odbl/1.0/. Any rights in individual contents of the database are licensed under the Database Contents License: http://opendatacommons.org/licenses/dbcl/1.0/\\\\n\\\\nThis work is licensed under the Creative Commons Attribution 4.0 Unported License.\\\\n\",', metadata={'source': '/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json', 'language': <Language.PYTHON: 'python'>})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"Who are the authors of this software?\")\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "qa_chain_instrucEmbed = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0.2, ),\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=retriever,\n",
    "                                                    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI's embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Warnings regarding parallelism and stack logging that are used within the library. To address these warnings,\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following lines gives an message: `RateLimitError` caused by reaching the rate limit for using the OpenAI Text Embedding API (text-embedding-ada-002). This API has a limitation on the number of tokens that can be processed within a certain time frame. The solution is to reduce the Input Size: As suggested in the error message, you can reduce the number of input tokens (text) in your request to stay within the rate limits of the Text Embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_openAIEmbedd= FAISS.from_documents(texts, embeddings)\n",
    "retriever_openai = db_openAIEmbedd.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "qa_chain_openai = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0.2, ),\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=retriever_openai,\n",
    "                                                    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing both MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "\n",
    "import textwrap # text wrapping and filling\n",
    "def wrap_text_preserve_newlines(text, width=79):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    #wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back into a single string using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\nSources:')\n",
    "    for source in llm_response['source_documents']:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Instructor Embeddings-------------\n",
      "\n",
      " The installation instructions for the Screenshot Service can be found in the\n",
      "README.md file on the project's GitHub page. The instructions are as follows:\n",
      "\n",
      "1. Clone the service: https://github.com/MPDL/screenshot-service\n",
      "2. Compile the service: In service directory, run `mvn clean install`\n",
      "3. Copy html-screenshot.war to Tomcat Webapp Directory\n",
      "4. Start Tomcat\n",
      "5. Run Services under `http://localhost:8080/screenshot`\n",
      "6. (OPTIONAL) If you want to support Webgl (only with useFirefox=true), you\n",
      "need:\n",
      "      * a: a server with a grafic card\n",
      "      * b: run `Xvfb :2 -screen 0 1024x768x24`\n",
      "      * c: run  `export DISPLAY=\":2\"`\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_joai-project_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n"
     ]
    }
   ],
   "source": [
    "query = 'Can you give me the installation instructions in detail for one of the software? Please indicate the project name and description'\n",
    "\n",
    "print('--------------Instructor Embeddings-------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------OpenAI Embeddings------------------\n",
      " I'm sorry, I don't know.\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'Can you give me the installation instructions in detail for one of the software? Please indicate the project name and description'\n",
    "\n",
    "print('-------------------OpenAI Embeddings------------------')\n",
    "llm_response = qa_chain_openai(query)\n",
    "process_llm_response(llm_response)\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Instructor Embeddings------------------\n",
      "\n",
      " The project is called unibiAPC and it is licensed under The MIT License (MIT).\n",
      "The installation requirements are:\n",
      "1. Install Firefox [download](https://www.mozilla.org/)\n",
      "2. Install Phantoms [download] (http://phantomjs.org/download.html)\n",
      "3. Install Java [download]\n",
      "(http://www.oracle.com/technetwork/java/javase/downloads/index.html)\n",
      "4. Install Maven [download] (http://maven.apache.org/download.cgi)\n",
      "5. Install Tomcat [download](http://maven.apache.org/download.cgi)\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json\n"
     ]
    }
   ],
   "source": [
    "query = 'Can you give me the installation requirements of a project using python? Please provide the title name and licence'\n",
    "\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Instructor Embeddings------------------\n",
      "\n",
      " The project is called unibiAPC and it is licensed under The MIT License (MIT).\n",
      "The installation requirements are:\n",
      "1. Install Firefox [download](https://www.mozilla.org/)\n",
      "2. Install Phantoms [download] (http://phantomjs.org/download.html)\n",
      "3. Install Java [download]\n",
      "(http://www.oracle.com/technetwork/java/javase/downloads/index.html)\n",
      "4. Install Maven [download] (http://maven.apache.org/download.cgi)\n",
      "5. Install Tomcat [download](http://maven.apache.org/download.cgi)\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json\n"
     ]
    }
   ],
   "source": [
    "query = 'Can you give me the installation requirements of a project using python? Please provide the title name and licence'\n",
    "\n",
    "# print('-------------------OpenAI Embeddings------------------')\n",
    "# llm_response = qa_chain_openai(query)\n",
    "# process_llm_response(llm_response)\n",
    "# print('\\n\\n\\n')\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Instructor Embeddings------------------\n",
      "\n",
      " No, I don't know the list of dependencies for a specific software package.\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_joai-project_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_rdmo-catalog_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you provide me the list of dependencies for a specific software package? Indicate the owner of the package and how to install it\"\n",
    "\n",
    "# print('-------------------OpenAI Embeddings------------------')\n",
    "# llm_response = qa_chain_openai(query)\n",
    "# process_llm_response(llm_response)\n",
    "# print('\\n\\n\\n')\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------OpenAI Embeddings------------------\n",
      " No, I don't know the answer to that question.\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you provide me the list of dependencies for a specific software package? Indicate the owner of the package and how to install it\"\n",
    "\n",
    "print('-------------------OpenAI Embeddings------------------')\n",
    "llm_response = qa_chain_openai(query)\n",
    "process_llm_response(llm_response)\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Instructor Embeddings------------------\n",
      "\n",
      " No, I cannot identify the software library dependencies of a readme.\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_rdmo-catalog_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_joai-project_2023-11-28.json\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you identify the `software library dependencies` of a readme?\"\n",
    "\n",
    "# print('-------------------OpenAI Embeddings------------------')\n",
    "# llm_response = qa_chain_openai(query)\n",
    "# process_llm_response(llm_response)\n",
    "# print('\\n\\n\\n')\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------OpenAI Embeddings------------------\n",
      " The documentation for the joai-project can be found at\n",
      "https://github.com/MPDL/joai-project/wiki and the documentation for the auth\n",
      "project can be found at https://github.com/MPDL/auth/wiki.\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_joai-project_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_auth_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_screenshot-service_2023-11-28.json\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Please provide a link to the documentation for each project?\"\n",
    "\n",
    "print('-------------------OpenAI Embeddings------------------')\n",
    "llm_response = qa_chain_openai(query)\n",
    "process_llm_response(llm_response)\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------OpenAI Embeddings------------------\n",
      " The names of the projects are: University of Sheffield, University of\n",
      "Southampton, University of St Andrews, University of Strathclyde, University of\n",
      "Surrey, University of Sussex, University of the West of England, University of\n",
      "Ulster, University of Warwick, and University of York.\n",
      "\n",
      "Sources:\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_unibiAPC_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_joai-project_2023-11-28.json\n",
      "/Users/ccugutrillague/Documents/outreach/smp-hackthaton/maSMP-LLM/data/mpdl_collection_raw/MPDL_auth_2023-11-28.json\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give me the list of names for all the project you find?\"\n",
    "\n",
    "print('-------------------OpenAI Embeddings------------------')\n",
    "llm_response = qa_chain_openai(query)\n",
    "process_llm_response(llm_response)\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
